{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K.clear_session() is useful when you're creating multiple models in succession, such as during hyperparameter search or cross-validation. Each model you train adds nodes (potentially numbering in the thousands) to the graph. TensorFlow executes the entire graph whenever you (or Keras) call tf.Session.run() or tf.Tensor.eval(), so your models will become slower and slower to train, and you may also run out of memory\n",
    "\n",
    "del will delete variable in python and since model is a variable, del model will delete it but the TF graph will have no changes (TF is your Keras backend). This said, K.clear_session() will destroy the current TF graph and creates a new one. Creating a new model seems to be an independent step, but don't forget the backend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../Utils')\n",
    "from metrics import compute_metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "import time\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary\n",
    "from gpflow.config import default_float\n",
    "import scipy.stats\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, '../../../Data/')\n",
    "\n",
    "RNA_PROT_EMBED = data_dir+'ProcessedData/protein_embeddings/rna_protein_u64embeddings.pkl'\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "#gpflow.config.set_default_float('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF eager exectution: True\n",
      "Using device PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "device = 1\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[device], 'GPU')\n",
    "\n",
    "print(f'TF eager exectution: {tf.executing_eagerly()}')\n",
    "print(f'Using device {physical_devices[device]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.ones((2, 2))\n",
    "\n",
    "# with tf.GradientTape() as t:\n",
    "#     t.watch(x)\n",
    "#     y = tf.reduce_sum(x)\n",
    "#     z = tf.multiply(y, y)\n",
    "\n",
    "# # Derivative of z with respect to the original input tensor x\n",
    "# dz_dx = t.gradient(z, x)\n",
    "# for i in [0, 1]:\n",
    "#     for j in [0, 1]:\n",
    "#         assert dz_dx[i][j].numpy() == 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session() #destroys graph and all values\n",
    "# keras.backend.reset_uids() #resets graph names, does not clear data?\n",
    "\n",
    "#Also have to do all below\n",
    "# Set (& reset) random seeds\n",
    "# Reset TensorFlow default graph\n",
    "# Delete previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with different activation functions, ReLu and log-sigmoid\n",
    "* Manifold GP uses activations after every output, try omitting final activation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class General_MLP(keras.Model):\n",
    "    def __init__(self,hidden_nodes,input_shape,activation='relu',last=False):\n",
    "        '''\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "        hidden nodes (array like) - all the dimensions after input including output size\n",
    "        input shape is optional (tuple), if not specified then network takes input shape as the shape of the first vector passed to it.\n",
    "        activation (string), type of activation function to use, must be in keras activations\n",
    "        last (Bool), whether or not to have activation on the final output layer\n",
    "        ex:\n",
    "        atlas_mlp = General_MLP([66,1],input_shape=(1,66))\n",
    "        atlas_mlp.summary()\n",
    "        '''\n",
    "        super(General_MLP, self).__init__()\n",
    "        self.mlp_layers = []\n",
    "        for nodes in hidden_nodes[0:-1]: \n",
    "            self.mlp_layers.append(keras.layers.Dense(nodes, activation=activation))\n",
    "            \n",
    "        if last:\n",
    "            self.mlp_layers.append(keras.layers.Dense(hidden_nodes[-1], activation=activation))\n",
    "        else:\n",
    "            self.mlp_layers.append(keras.layers.Dense(hidden_nodes[-1]))\n",
    "            \n",
    "        #Specific line is to cast the output to the gpflow default precision\n",
    "        self.mlp_layers.append(tf.keras.layers.Lambda(lambda x: tf.cast(x, default_float())))\n",
    "        self.out_size = hidden_nodes[-1]\n",
    "        \n",
    "        if type(input_shape) != type(None):\n",
    "            self.in_size = input_shape[1]\n",
    "            self.build(input_shape)\n",
    "    \n",
    "    #training flag if specific layers behave differently (ex: batch norm), for mlp no difference\n",
    "    def call(self, inputs, training=True):\n",
    "        for layer in self.mlp_layers:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_based_kernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self,base_kernel: gpflow.kernels.Kernel,nn_model):\n",
    "        super(nn_based_kernel, self).__init__()\n",
    "        assert(nn_model.built),\"NN model is not built, input shape is not initialized\"\n",
    "\n",
    "        self.model = nn_model\n",
    "        self.base_kernel = base_kernel\n",
    "    \n",
    "    def K(self,X,X2=None,presliced=False):\n",
    "        \"\"\"\n",
    "        If you add a method in the child class with the same name as a function in the\n",
    "        parent class, the inheritance of the parent method will be overridden.\n",
    "        \"\"\"\n",
    "        transformed_X = self.model(X)\n",
    "        transformed_X2 = self.model(X2) if X2 is not None else X2\n",
    "        return self.base_kernel.K(transformed_X, transformed_X2, presliced)\n",
    "    \n",
    "    def K_diag(self, X_input,presliced=False):\n",
    "        transformed_X = self.model(X_input)\n",
    "        return self.base_kernel.K_diag(transformed_X, presliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RNA_PROT_EMBED,'rb') as file:\n",
    "    rna_prot_embed = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mRNA_TMM</th>\n",
       "      <th>ProteinAUC</th>\n",
       "      <th>ProteinLength</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th>Majority.protein.IDs</th>\n",
       "      <th>cell</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pfdn5</th>\n",
       "      <th>Q9WU28</th>\n",
       "      <th>AM_04M_F0</th>\n",
       "      <td>6.720281</td>\n",
       "      <td>24.667465</td>\n",
       "      <td>7.276124</td>\n",
       "      <td>-0.052385</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>-0.154599</td>\n",
       "      <td>-0.968072</td>\n",
       "      <td>-0.048646</td>\n",
       "      <td>-0.057724</td>\n",
       "      <td>0.090963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081625</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>-0.068875</td>\n",
       "      <td>-0.052846</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>-0.201325</td>\n",
       "      <td>-0.040759</td>\n",
       "      <td>0.425445</td>\n",
       "      <td>0.012814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plp2</th>\n",
       "      <th>Q9R1Q7</th>\n",
       "      <th>AM_04M_F0</th>\n",
       "      <td>5.830972</td>\n",
       "      <td>25.775840</td>\n",
       "      <td>7.257388</td>\n",
       "      <td>-0.033052</td>\n",
       "      <td>0.134889</td>\n",
       "      <td>0.141637</td>\n",
       "      <td>-0.956040</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>-0.182095</td>\n",
       "      <td>0.130975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132585</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.125836</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>-0.140103</td>\n",
       "      <td>0.380313</td>\n",
       "      <td>-0.058217</td>\n",
       "      <td>-0.033651</td>\n",
       "      <td>0.610501</td>\n",
       "      <td>-0.012678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tmem14c</th>\n",
       "      <th>Q9CQN6</th>\n",
       "      <th>AM_04M_F0</th>\n",
       "      <td>7.550046</td>\n",
       "      <td>24.936248</td>\n",
       "      <td>6.845490</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>0.217301</td>\n",
       "      <td>0.261191</td>\n",
       "      <td>-0.960215</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>-0.281522</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110375</td>\n",
       "      <td>0.034658</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.107524</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>-0.164854</td>\n",
       "      <td>-0.057921</td>\n",
       "      <td>0.757256</td>\n",
       "      <td>-0.136181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gripap1</th>\n",
       "      <th>Q8VD04</th>\n",
       "      <th>AM_04M_F0</th>\n",
       "      <td>6.091160</td>\n",
       "      <td>24.181408</td>\n",
       "      <td>9.656425</td>\n",
       "      <td>-0.122346</td>\n",
       "      <td>0.178826</td>\n",
       "      <td>-0.164156</td>\n",
       "      <td>-0.985093</td>\n",
       "      <td>-0.164132</td>\n",
       "      <td>0.041334</td>\n",
       "      <td>0.059079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129590</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>-0.081749</td>\n",
       "      <td>0.101627</td>\n",
       "      <td>0.551019</td>\n",
       "      <td>-0.219265</td>\n",
       "      <td>0.074746</td>\n",
       "      <td>0.187250</td>\n",
       "      <td>0.138466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psme2</th>\n",
       "      <th>P97372</th>\n",
       "      <th>AM_04M_F0</th>\n",
       "      <td>6.540118</td>\n",
       "      <td>25.459281</td>\n",
       "      <td>7.906891</td>\n",
       "      <td>-0.062492</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>-0.111893</td>\n",
       "      <td>-0.981987</td>\n",
       "      <td>-0.052023</td>\n",
       "      <td>-0.045305</td>\n",
       "      <td>0.066097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.038291</td>\n",
       "      <td>-0.074381</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.349252</td>\n",
       "      <td>-0.088379</td>\n",
       "      <td>-0.027900</td>\n",
       "      <td>0.313307</td>\n",
       "      <td>0.037586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mRNA_TMM  ProteinAUC  \\\n",
       "Gene.names Majority.protein.IDs cell                              \n",
       "Pfdn5      Q9WU28               AM_04M_F0  6.720281   24.667465   \n",
       "Plp2       Q9R1Q7               AM_04M_F0  5.830972   25.775840   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0  7.550046   24.936248   \n",
       "Gripap1    Q8VD04               AM_04M_F0  6.091160   24.181408   \n",
       "Psme2      P97372               AM_04M_F0  6.540118   25.459281   \n",
       "\n",
       "                                           ProteinLength         0         1  \\\n",
       "Gene.names Majority.protein.IDs cell                                           \n",
       "Pfdn5      Q9WU28               AM_04M_F0       7.276124 -0.052385  0.085488   \n",
       "Plp2       Q9R1Q7               AM_04M_F0       7.257388 -0.033052  0.134889   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0       6.845490 -0.014391  0.217301   \n",
       "Gripap1    Q8VD04               AM_04M_F0       9.656425 -0.122346  0.178826   \n",
       "Psme2      P97372               AM_04M_F0       7.906891 -0.062492  0.085542   \n",
       "\n",
       "                                                  2         3         4  \\\n",
       "Gene.names Majority.protein.IDs cell                                      \n",
       "Pfdn5      Q9WU28               AM_04M_F0 -0.154599 -0.968072 -0.048646   \n",
       "Plp2       Q9R1Q7               AM_04M_F0  0.141637 -0.956040 -0.004309   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0  0.261191 -0.960215  0.016086   \n",
       "Gripap1    Q8VD04               AM_04M_F0 -0.164156 -0.985093 -0.164132   \n",
       "Psme2      P97372               AM_04M_F0 -0.111893 -0.981987 -0.052023   \n",
       "\n",
       "                                                  5         6  ...        54  \\\n",
       "Gene.names Majority.protein.IDs cell                           ...             \n",
       "Pfdn5      Q9WU28               AM_04M_F0 -0.057724  0.090963  ...  0.081625   \n",
       "Plp2       Q9R1Q7               AM_04M_F0 -0.182095  0.130975  ...  0.132585   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0 -0.281522  0.232086  ...  0.110375   \n",
       "Gripap1    Q8VD04               AM_04M_F0  0.041334  0.059079  ...  0.129590   \n",
       "Psme2      P97372               AM_04M_F0 -0.045305  0.066097  ...  0.122180   \n",
       "\n",
       "                                                 55        56        57  \\\n",
       "Gene.names Majority.protein.IDs cell                                      \n",
       "Pfdn5      Q9WU28               AM_04M_F0  0.026748 -0.068875 -0.052846   \n",
       "Plp2       Q9R1Q7               AM_04M_F0  0.024357  0.125836 -0.011633   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0  0.034658  0.044476 -0.000788   \n",
       "Gripap1    Q8VD04               AM_04M_F0  0.057372 -0.006390 -0.081749   \n",
       "Psme2      P97372               AM_04M_F0  0.014133  0.038291 -0.074381   \n",
       "\n",
       "                                                 58        59        60  \\\n",
       "Gene.names Majority.protein.IDs cell                                      \n",
       "Pfdn5      Q9WU28               AM_04M_F0  0.016210  0.417333 -0.201325   \n",
       "Plp2       Q9R1Q7               AM_04M_F0 -0.140103  0.380313 -0.058217   \n",
       "Tmem14c    Q9CQN6               AM_04M_F0 -0.107524  0.604052 -0.164854   \n",
       "Gripap1    Q8VD04               AM_04M_F0  0.101627  0.551019 -0.219265   \n",
       "Psme2      P97372               AM_04M_F0  0.006843  0.349252 -0.088379   \n",
       "\n",
       "                                                 61        62        63  \n",
       "Gene.names Majority.protein.IDs cell                                     \n",
       "Pfdn5      Q9WU28               AM_04M_F0 -0.040759  0.425445  0.012814  \n",
       "Plp2       Q9R1Q7               AM_04M_F0 -0.033651  0.610501 -0.012678  \n",
       "Tmem14c    Q9CQN6               AM_04M_F0 -0.057921  0.757256 -0.136181  \n",
       "Gripap1    Q8VD04               AM_04M_F0  0.074746  0.187250  0.138466  \n",
       "Psme2      P97372               AM_04M_F0 -0.027900  0.313307  0.037586  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code Parameters\n",
    "#-----------------------------------------\n",
    "cols_drop=['ProteinAUC']\n",
    "MRNA_THRESH = 0\n",
    "ZSCORE = True\n",
    "BATCH = 32\n",
    "SAVE = False\n",
    "LOG_TRANS = True\n",
    "#-----------------------------------------\n",
    "\n",
    "data = rna_prot_embed['AM_04M_F0'].copy()\n",
    "data.drop(columns='AvgChrs',inplace=True)\n",
    "data = data[data['mRNA_TMM']>MRNA_THRESH]\n",
    "\n",
    "if LOG_TRANS:\n",
    "    #Log transform mRNA, protein, and protein length -> log-normal distributed\n",
    "    data['mRNA_TMM'] = np.log2(data['mRNA_TMM']+1)\n",
    "    data['ProteinAUC'] = np.log2(data['ProteinAUC']+1)\n",
    "    data['ProteinLength'] = np.log2(data['ProteinLength']+1)\n",
    "\n",
    "SEED = 10\n",
    "train,test = train_test_split(data,test_size=0.2,random_state=SEED)\n",
    "SEED = 42\n",
    "test,val = train_test_split(test,test_size=0.5,random_state=SEED)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try not transforming embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is z-scored\n"
     ]
    }
   ],
   "source": [
    "def zscore(train_df):\n",
    "    assert isinstance(train_df,pd.DataFrame)\n",
    "    means = train_df.mean(axis=0)\n",
    "    stds = train_df.std(axis=0)\n",
    "    zscored = (train_df-means)/stds\n",
    "    return zscored, means, stds\n",
    "\n",
    "if ZSCORE:\n",
    "    print(f'Data is z-scored')\n",
    "    train, train_mean, train_std = zscore(train) #zscore data\n",
    "    val = (val-train_mean)/train_std #zscore validation data using mean and std from train set\n",
    "    test = (test-train_mean)/train_std #zscore test data using mean and std from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: (2859, 66)\n",
      "validation dataset size: (358, 66)\n",
      "test dataset size: (357, 66)\n"
     ]
    }
   ],
   "source": [
    "x_train = train.drop(columns=cols_drop).values\n",
    "y_train = train[['ProteinAUC']].values\n",
    "\n",
    "x_val = val.drop(columns=cols_drop).values\n",
    "y_val = val[['ProteinAUC']].values\n",
    "\n",
    "x_test = test.drop(columns=cols_drop).values\n",
    "y_test = test[['ProteinAUC']].values\n",
    "\n",
    "print(f'train dataset size: {x_train.shape}')\n",
    "print(f'validation dataset size: {x_val.shape}')\n",
    "print(f'test dataset size: {x_test.shape}')\n",
    "\n",
    "trn_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "trn_dataset = trn_dataset.shuffle(buffer_size=x_train.shape[0]).batch(BATCH) #I think default is 32\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_dataset = val_dataset.batch(BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"general_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  1072      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  51        \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,123\n",
      "Trainable params: 1,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "manifold_mlp = General_MLP([16,3],input_shape=(1,66),last=True,activation='sigmoid')\n",
    "manifold_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold GP and Kernel Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people who set up a GP regression or classification model end up using the Squared-Exp or Rational Quadratic kernels. They are a quick-and-dirty solution that will probably work pretty well for interpolating smooth functions when N is a multiple of D, and when there are no 'kinks' in your function. If your function happens to have a discontinuity or is discontinuous in its first few derivatives (for example, the abs() function), then either your lengthscale will end up being extremely short, and your posterior mean will become zero almost everywhere, or your posterior mean will have 'ringing' effects. Even if there are no hard discontinuities, the lengthscale will usually end up being determined by the smallest 'wiggle' in your function - so you might end up failing to extrapolate in smooth regions if there is even a small non-smooth region in your data.\n",
    "\n",
    "If your data is more than two-dimensional, it may be hard to detect this problem. One indication is if the lengthscale chosen by maximum marginal likelihood never stops becoming smaller as you add more data. This is a classic sign of model misspecification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                class             transform                prior    trainable    shape     dtype    value\n",
      "----------------------------------  ----------------  -----------------------  -------  -----------  --------  -------  -----------------------------------------\n",
      "GPR.kernel.model._layers[0][0]._trainable_weights[0]\n",
      "GPR.kernel.model._layers[0][0].kernel\n",
      "GPR.kernel.model.mlp_layers[0]._trainable_weights[0]\n",
      "GPR.kernel.model.mlp_layers[0].kernel                                     ResourceVariable                                    True         (66, 16)  float64  [[-0.14793625, 0.26699009, -0.20935757...\n",
      "GPR.kernel.model._layers[0][0]._trainable_weights[1]\n",
      "GPR.kernel.model._layers[0][0].bias\n",
      "GPR.kernel.model.mlp_layers[0]._trainable_weights[1]\n",
      "GPR.kernel.model.mlp_layers[0].bias                                     ResourceVariable                                    True         (16,)     float64  [0., 0., 0....\n",
      "GPR.kernel.model._layers[0][1]._trainable_weights[0]\n",
      "GPR.kernel.model._layers[0][1].kernel\n",
      "GPR.kernel.model.mlp_layers[1]._trainable_weights[0]\n",
      "GPR.kernel.model.mlp_layers[1].kernel                                     ResourceVariable                                    True         (16, 3)   float64  [[0.0199605, -0.53501687, 0.31624301...\n",
      "GPR.kernel.model._layers[0][1]._trainable_weights[1]\n",
      "GPR.kernel.model._layers[0][1].bias\n",
      "GPR.kernel.model.mlp_layers[1]._trainable_weights[1]\n",
      "GPR.kernel.model.mlp_layers[1].bias                                     ResourceVariable                                    True         (3,)      float64  [0. 0. 0.]\n",
      "GPR.kernel.base_kernel.variance     Parameter         Softplus                          True         ()        float64  1.0\n",
      "GPR.kernel.base_kernel.lengthscale  Parameter         Softplus                          True         (3,)      float64  [1. 1. 1.]\n",
      "GPR.likelihood.variance             Parameter         Softplus + AffineScalar           True         ()        float64  0.1000000014901161\n"
     ]
    }
   ],
   "source": [
    "base_kernel = gpflow.kernels.SquaredExponential(lengthscale=[1]*manifold_mlp.out_size) #Initialize ARD for lengthscale\n",
    "k = nn_based_kernel(base_kernel,manifold_mlp)\n",
    "#print_summary(kernel)\n",
    "\n",
    "model = gpflow.models.GPR(data=(x_train, y_train), kernel=k, mean_function=None)\n",
    "model.likelihood.variance.assign(0.1)\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPR is not typically trained with stochastic/batch gradient descent\n",
    "* Use all data typically to optimize marginal likelihood, (bfgs, conjugate gradients, full gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare model.trainable_parameters to print_summary output\n",
    "#what is difference between model.trainable_parameters and model.kernel.trainable_variables\n",
    "\n",
    "#https://gpflow.readthedocs.io/en/latest/notebooks/models.html\n",
    "#print_summary gives the untransformed parameters\n",
    "#transform is softplus and the inverse given below\n",
    "#np.log(1+np.e**0.54132485) = 1\n",
    "#np.log((np.e**1)-1) = 0.54132485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense/bias:0' shape=(16,) dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float64, numpy=array([0., 0., 0.])>\n"
     ]
    }
   ],
   "source": [
    "for layer in manifold_mlp.weights:\n",
    "    if 'bias' in layer.name:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unoptimized mapped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unmapped = model.kernel.model(x_train).numpy()\n",
    "xtest_unmapped = model.kernel.model(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deb38c0746c46b087a4f1d4e3a9c0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(9.5,6.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = x_unmapped[:,0]\n",
    "y = x_unmapped[:,1]\n",
    "z = x_unmapped[:,2]\n",
    "c = y_train[:,0]\n",
    "# x = np.random.standard_normal(100)\n",
    "# y = np.random.standard_normal(100)\n",
    "# z = np.random.standard_normal(100)\n",
    "# c = np.random.standard_normal(100)\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/42424444/scipy-optimisation-newton-cg-vs-bfgs-vs-l-bfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS? or L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFGS = False\n",
    "if BFGS:\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "\n",
    "    def objective_closure():\n",
    "        return - model.log_marginal_likelihood()\n",
    "\n",
    "    time_start = time.time()\n",
    "    opt_logs = opt.minimize(objective_closure,\n",
    "                            model.trainable_variables,\n",
    "                            options=dict(maxiter=1))\n",
    "    print(f'Run time {time.time()-time_start}')\n",
    "\n",
    "    print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking kernel parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_likelihood = list()\n",
    "neg_likelihood.append(-model.log_marginal_likelihood())\n",
    "\n",
    "lengthscales = model.kernel.base_kernel.lengthscale.numpy().copy()\n",
    "#np.vstack((model.kernel.base_kernel.lengthscale.numpy(),model.kernel.base_kernel.lengthscale.numpy()))\n",
    "\n",
    "kernel_variance = list()\n",
    "kernel_variance.append(model.kernel.base_kernel.variance.numpy())\n",
    "\n",
    "model_variance = list()\n",
    "model_variance.append(model.likelihood.variance.numpy())\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting neg likelihood 12994.701236667945\n",
      "ending neg likelihood 2162.169613679592\n"
     ]
    }
   ],
   "source": [
    "ADAM = True\n",
    "print(f'starting neg likelihood {-model.log_marginal_likelihood()}')\n",
    "if ADAM:\n",
    "    iterations = 4000\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # disable automatic tracking by passing watch_accessed_variables=False\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "            tape.watch(model.trainable_variables)\n",
    "            obj = -model.log_marginal_likelihood()\n",
    "        grads = tape.gradient(obj, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        neg_likelihood.append(-model.log_marginal_likelihood())\n",
    "        lengthscales = np.vstack((lengthscales,model.kernel.base_kernel.lengthscale.numpy().copy()))\n",
    "        kernel_variance.append(model.kernel.base_kernel.variance.numpy())\n",
    "        model_variance.append(model.likelihood.variance.numpy())\n",
    "    \n",
    "print(f'ending neg likelihood {-model.log_marginal_likelihood()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a216b8b9599349f1a80b6fd2cb159413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1b507df110>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(12.5,12.5)\n",
    "ax = fig.add_subplot(321)\n",
    "ax.plot(range(0,len(neg_likelihood)),neg_likelihood)\n",
    "\n",
    "ax = fig.add_subplot(322)\n",
    "ax.plot(range(0,len(kernel_variance)),kernel_variance)\n",
    "\n",
    "ax = fig.add_subplot(323)\n",
    "ax.plot(range(0,len(model_variance)),model_variance)\n",
    "\n",
    "ax = fig.add_subplot(324)\n",
    "ax.plot(range(0,len(lengthscales[:,0])),lengthscales[:,0])\n",
    "ax = fig.add_subplot(325)\n",
    "ax.plot(range(0,len(lengthscales[:,1])),lengthscales[:,1])\n",
    "ax = fig.add_subplot(326)\n",
    "ax.plot(range(0,len(lengthscales[:,2])),lengthscales[:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mapped = model.kernel.model(x_train).numpy()\n",
    "xtest_mapped = model.kernel.model(x_test).numpy()\n",
    "x_val_mapped = model.kernel.model(x_val).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2859, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879c392cc9f54f139ea24dbb163ae878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(9.5,6.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = x_mapped[:,0]\n",
    "y = x_mapped[:,1]\n",
    "z = x_mapped[:,2]\n",
    "c = y_train[:,0]\n",
    "# x = np.random.standard_normal(100)\n",
    "# y = np.random.standard_normal(100)\n",
    "# z = np.random.standard_normal(100)\n",
    "# c = np.random.standard_normal(100)\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d354543cb0b4547a35c29cd1c8df42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(9.5,6.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = xtest_mapped[:,0]\n",
    "y = xtest_mapped[:,1]\n",
    "z = xtest_mapped[:,2]\n",
    "c = y_test[:,0]\n",
    "# x = np.random.standard_normal(100)\n",
    "# y = np.random.standard_normal(100)\n",
    "# z = np.random.standard_normal(100)\n",
    "# c = np.random.standard_normal(100)\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9348df0ca44d42088239a69180eeec89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(9.5,6.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = x_val_mapped[:,0]\n",
    "y = x_val_mapped[:,1]\n",
    "z = x_val_mapped[:,2]\n",
    "c = y_val[:,0]\n",
    "# x = np.random.standard_normal(100)\n",
    "# y = np.random.standard_normal(100)\n",
    "# z = np.random.standard_normal(100)\n",
    "# c = np.random.standard_normal(100)\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.6850242377732171,\n",
       " 'mse': 0.7854160520154855,\n",
       " 'smse': 0.8767397065488248,\n",
       " 'r2': 0.12326029345117517,\n",
       " 'evs': 0.12361854095630698,\n",
       " 'spearmanrho': 0.5238885956025708,\n",
       " 'spearmanrho_p': 1.2627634757795259e-26,\n",
       " 'pearsonr': 0.5523811139202937,\n",
       " 'pearsonr_p': 5.499876041168695e-30,\n",
       " 'median_abs_fc': 1.4683280931317197,\n",
       " 'mean_abs_fc': 1.6077289916598017}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict mean and variance of latent GP at test points\n",
    "mean, var = model.predict_f(x_val)\n",
    "metrics = compute_metrics(mean.numpy(), y_val, y_val, fc_scale=2)\n",
    "\n",
    "# if SAVE:\n",
    "#     pd.DataFrame.from_dict(metrics,orient='index').T.to_csv(f'./results/am04f0/metrics_{TITLE}.tsv',sep='\\t')\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.3879635710486783,\n",
       " 'mse': 0.2578142860925523,\n",
       " 'smse': 0.25790449403030363,\n",
       " 'r2': 0.7420955059696963,\n",
       " 'evs': 0.7420955489191499,\n",
       " 'spearmanrho': 0.8283834226158453,\n",
       " 'spearmanrho_p': 0.0,\n",
       " 'pearsonr': 0.8614553636588064,\n",
       " 'pearsonr_p': 0.0,\n",
       " 'median_abs_fc': 1.2420002972373432,\n",
       " 'mean_abs_fc': 1.3085450294581435}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict mean and variance of latent GP at test points\n",
    "mean, var = model.predict_f(x_train)\n",
    "metrics = compute_metrics(mean.numpy(), y_train, y_train, fc_scale=2)\n",
    "\n",
    "# if SAVE:\n",
    "#     pd.DataFrame.from_dict(metrics,orient='index').T.to_csv(f'./results/am04f0/metrics_{TITLE}.tsv',sep='\\t')\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218681192a3a450ab29c34cb1d0e9a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(mean.numpy(),y_train)\n",
    "y_max = int(y_train.max())+2\n",
    "y_min = y_train.min()-2\n",
    "ax.set_xlim(y_min,y_max)\n",
    "ax.set_ylim(y_min,y_max)\n",
    "\n",
    "x = np.linspace(*ax.get_xlim())\n",
    "# ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "ax.plot(x, x,color='k',linewidth=3)\n",
    "\n",
    "pearson = scipy.stats.pearsonr(y_train.squeeze(),mean.numpy().squeeze())[0]\n",
    "ax.text(.75,.01,f'pearson r: {pearson:.4f}',transform=ax.transAxes)\n",
    "if SAVE:\n",
    "    fig.savefig(f\"./results/am04f0/test_predicted_{TITLE}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe5eefec0fa4eedabb5356ccdb7332f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot mse, smse, and pearsonr for top 10% lowest variance to all, compute every 5% increments\n",
    "sorted_indicies = np.argsort(var.numpy().squeeze())\n",
    "sorted_mean = mean.numpy()[sorted_indicies]\n",
    "sorted_ytruth = y_train[sorted_indicies]\n",
    "\n",
    "scores=[]\n",
    "\n",
    "intervals = np.arange(.1,1.01,0.01)\n",
    "\n",
    "index_old = 0\n",
    "for percent in intervals:\n",
    "    index = int(np.floor(sorted_mean.shape[0]*percent))\n",
    "    top_means = sorted_mean[index_old:index]\n",
    "    top_means_ytruth = sorted_ytruth[index_old:index]\n",
    "    scores.append(compute_metrics(top_means, top_means_ytruth, y_train, fc_scale=2)['pearsonr'])\n",
    "    #print(metrics.mean_squared_error(top_means_ytruth,top_means))\n",
    "    #index_old = index\n",
    "    \n",
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(intervals,scores)\n",
    "if SAVE:\n",
    "    fig.savefig(f\"./results/am04f0/smse_{TITLE}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28857164e2eb4eda9d0190fc02eacb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.75, 0.01, 'pearson r: 0.9532')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent=1\n",
    "lower_percent=.9\n",
    "index = int(np.floor(sorted_mean.shape[0]*percent))\n",
    "lower_index = int(np.floor(sorted_mean.shape[0]*lower_percent))\n",
    "top_means = sorted_mean[lower_index:index]\n",
    "top_means_ytruth = sorted_ytruth[lower_index:index]\n",
    "\n",
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(top_means,top_means_ytruth)\n",
    "y_max = int(y_train.max())+2\n",
    "y_min = y_train.min()-2\n",
    "ax.set_xlim(y_min,y_max)\n",
    "ax.set_ylim(y_min,y_max)\n",
    "\n",
    "x = np.linspace(*ax.get_xlim())\n",
    "# ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "ax.plot(x, x,color='k',linewidth=3)\n",
    "\n",
    "pearson = scipy.stats.pearsonr(top_means_ytruth.squeeze(),top_means.squeeze())[0]\n",
    "ax.text(.75,.01,f'pearson r: {pearson:.4f}',transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.6860972190871452,\n",
       " 'mse': 0.8154166875830106,\n",
       " 'smse': 0.6937341193181213,\n",
       " 'r2': 0.3062113084884177,\n",
       " 'evs': 0.3079801035706219,\n",
       " 'spearmanrho': 0.5639833863367707,\n",
       " 'spearmanrho_p': 2.2944398562028135e-31,\n",
       " 'pearsonr': 0.6188788044263925,\n",
       " 'pearsonr_p': 4.047824850545014e-39,\n",
       " 'median_abs_fc': 1.4457317979430908,\n",
       " 'mean_abs_fc': 1.6089251590895808}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict mean and variance of latent GP at test points\n",
    "mean, var = model.predict_f(x_test)\n",
    "metrics = compute_metrics(mean.numpy(), y_test, y_train, fc_scale=2)\n",
    "\n",
    "# if SAVE:\n",
    "#     pd.DataFrame.from_dict(metrics,orient='index').T.to_csv(f'./results/am04f0/metrics_{TITLE}.tsv',sep='\\t')\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca439e01aebb4ad487205e0f5158c14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(mean.numpy(),y_test)\n",
    "y_max = int(y_test.max())+2\n",
    "y_min = y_test.min()-2\n",
    "ax.set_xlim(y_min,y_max)\n",
    "ax.set_ylim(y_min,y_max)\n",
    "\n",
    "x = np.linspace(*ax.get_xlim())\n",
    "# ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "ax.plot(x, x,color='k',linewidth=3)\n",
    "\n",
    "pearson = scipy.stats.pearsonr(y_test.squeeze(),mean.numpy().squeeze())[0]\n",
    "ax.text(.75,.01,f'pearson r: {pearson:.4f}',transform=ax.transAxes)\n",
    "if SAVE:\n",
    "    fig.savefig(f\"./results/am04f0/test_predicted_{TITLE}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbf699e97924261ac7698447655c541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot mse, smse, and pearsonr for top 10% lowest variance to all, compute every 5% increments\n",
    "sorted_indicies = np.argsort(var.numpy().squeeze())\n",
    "sorted_mean = mean.numpy()[sorted_indicies]\n",
    "sorted_ytruth = y_test[sorted_indicies]\n",
    "\n",
    "scores=[]\n",
    "\n",
    "intervals = np.arange(.1,1.01,0.01)\n",
    "\n",
    "index_old = 0\n",
    "for percent in intervals:\n",
    "    index = int(np.floor(sorted_mean.shape[0]*percent))\n",
    "    top_means = sorted_mean[index_old:index]\n",
    "    top_means_ytruth = sorted_ytruth[index_old:index]\n",
    "    scores.append(compute_metrics(top_means, top_means_ytruth, y_train, fc_scale=2)['smse'])\n",
    "    #print(metrics.mean_squared_error(top_means_ytruth,top_means))\n",
    "    index_old = index\n",
    "    \n",
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(intervals,scores)\n",
    "if SAVE:\n",
    "    fig.savefig(f\"./results/am04f0/smse_{TITLE}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3971f9cc92db46f3a5ff5f70c9c0f8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.75, 0.01, 'pearson r: 0.4830')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent=.5\n",
    "lower_percent=0\n",
    "index = int(np.floor(sorted_mean.shape[0]*percent))\n",
    "lower_index = int(np.floor(sorted_mean.shape[0]*lower_percent))\n",
    "top_means = sorted_mean[lower_index:index]\n",
    "top_means_ytruth = sorted_ytruth[lower_index:index]\n",
    "\n",
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(top_means,top_means_ytruth)\n",
    "y_max = int(y_train.max())+2\n",
    "y_min = y_train.min()-2\n",
    "ax.set_xlim(y_min,y_max)\n",
    "ax.set_ylim(y_min,y_max)\n",
    "\n",
    "x = np.linspace(*ax.get_xlim())\n",
    "# ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "ax.plot(x, x,color='k',linewidth=3)\n",
    "\n",
    "pearson = scipy.stats.pearsonr(top_means_ytruth.squeeze(),top_means.squeeze())[0]\n",
    "ax.text(.75,.01,f'pearson r: {pearson:.4f}',transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4087433ced3f436eb6b95c071883bb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot mse, smse, and pearsonr for top 10% lowest variance to all, compute every 5% increments\n",
    "sorted_indicies = np.argsort(var.numpy().squeeze())\n",
    "sorted_mean = mean.numpy()[sorted_indicies]\n",
    "sorted_ytruth = y_test[sorted_indicies]\n",
    "\n",
    "scores=[]\n",
    "\n",
    "intervals = np.arange(.1,1.01,0.01)\n",
    "for percent in intervals:\n",
    "    index = int(np.floor(sorted_mean.shape[0]*percent))\n",
    "    top_means = sorted_mean[0:index]\n",
    "    top_means_ytruth = sorted_ytruth[0:index]\n",
    "    scores.append(compute_metrics(top_means, top_means_ytruth, y_train, fc_scale=2)['pearsonr'])\n",
    "    #print(metrics.mean_squared_error(top_means_ytruth,top_means))\n",
    "    \n",
    "fig = plt.figure()\n",
    "#fig.set_size_inches(10.5,10.5)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(intervals,scores)\n",
    "if SAVE:\n",
    "    fig.savefig(f\"./results/am04f0/smse_{TITLE}.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
